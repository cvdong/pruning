# Pruning

## æ¨¡å‹å‰ªæ â„¢ï¸

#### 1. Torch-Pruning

![](./images/intro.png)

* paper: [DepGraph: Towards Any Structural Pruning](https://arxiv.org/abs/2301.12900)
* github: [https://github.com/VainF/Torch-Pruning](https://github.com/VainF/Torch-Pruning)

å…³äºæ¨¡å‹å‰ªæè¿™è¾¹æ¨èä¸€ç§**é€šç”¨çš„ç»“æ„åŒ–å‰ªæå·¥å…·**[Torch-Pruning](https://github.com/VainF/Torch-Pruning),ä¸åŒäºtorch.nn.utils.pruneä¸­åˆ©ç”¨æ©ç (Masking)å®ç°çš„â€œæ¨¡æ‹Ÿå‰ªæâ€, Torch-Pruningé‡‡ç”¨äº†ä¸€ç§åä¸ºDepGraphçš„éæ·±åº¦å›¾ç®—æ³•, èƒ½å¤Ÿâ€œç‰©ç†â€åœ°ç§»é™¤æ¨¡å‹ä¸­çš„è€¦åˆå‚æ•°å’Œé€šé“-->ğŸš€è¯¦ç»†è®²è§£è¯·ç§»æ­¥å®˜æ–¹repoã€‚

(1) install

```
pip install torch-pruning
```

(2) yolov8_prune

```
git clone https://github.com/ultralytics/ultralytics.git 
cp yolov8_pruning.py ultralytics/
cd ultralytics 
git checkout 44c7c3514d87a5e05cfb14dba5a3eeb6eb860e70 # for compatibility
python yolov8_pruning.py
```

æ³¨æ„ï¼š æ¨¡å‹è®­ç»ƒ ultralytics ç‰ˆæœ¬ä¸€å®šå’Œå‰ªæç‰ˆæœ¬å¯¹åº”ï¼Œç›®å‰æµ‹è¯•ç‰ˆæœ¬ ultralytics==8.0.90.

#### 2. Prune

å‰ªæåŸç†æ¢ç´¢

[ç‚¹æˆ‘](https://u1g62ufvk30.feishu.cn/docx/MVrfdvgZfo6cQ3xeSkEcBLcKnrf)

Yolov8çš„é€šé“å‰ªææ–¹æ¡ˆ(bnå‰ªæ):

---

è®­ç»ƒbaseline --> ç¨€ç–åŒ–è®­ç»ƒ --> å‰ªæ --> å¾®è°ƒ

æ­¥éª¤å¦‚ä¸‹ï¼š

#### (1) è®­ç»ƒ

```
from ultralytics import YOLO

# Load a model
# model = YOLO("yolov8n.yaml")  # build a new model from scratch
model = YOLO("best.pt")  # load a pretrained model (recommended for training)

# Use the model
model.train(data="XX.yaml", epochs=100, batch=32, amp=False)  # train the model

metrics = model.val()  # evaluate model performance on the validation set
# results = model("https://ultralytics.com/images/bus.jpg")  # predict on an image

```

#### (2) ç¨€ç–åŒ–è®­ç»ƒ

```
# FILE: ultralytics/yolo/engine/trainer.py
...
# Backward
self.scaler.scale(self.loss).backward()

# <============ added
l1_lambda = 1e-2 * (1 - 0.9 * epoch / self.epochs)
for k, m in self.model.named_modules():
    if isinstance(m, nn.BatchNorm2d):
        m.weight.grad.data.add_(l1_lambda * torch.sign(m.weight.data))
        m.bias.grad.data.add_(1e-2 * torch.sign(m.bias.data))

# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html
if ni - last_opt_step >= self.accumulate:
    self.optimizer_step()
    last_opt_step = ni
...
```

#### (3) å‰ªæ

```
python prune.py  
```

#### (4) å¾®è°ƒ

* å»æ‰ l1 çº¦æŸ
* é¿å…ä»yaml å¯¼å…¥æ¨¡å‹ç»“æ„

```
# FILE: ultralytics/yolo/engine/model.py
# self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)
# self.model = self.trainer.model
self.trainer.model = self.model.train()
```

#### (5) onnx

```
from ultralytics import YOLO
import sys

# Load a model
model = YOLO("/home/DONG/PRUNE/ultralytics/runs/detect/train6/weights/best.pt")  # load a pretrained model (recommended for training)

# success = model.export(format="onnx", opset=13, half=True)  # export the model to ONNX format
success = model.export(format="onnx", simplify=True, opset=13, half=True) 
print(success)
```

#### (6) engine

```
trtexec --onnx=best.onnx  --saveEngine=best.engine --fp16
```

### 3. éƒ¨ç½²

[https://github.com/cvdong/YOLO_TRT_SIM](https://github.com/cvdong/YOLO_TRT_SIM)

å‰ªææ¯”ä¾‹ï¼š50%
æ€§èƒ½å¯¹æ¯”ï¼štensorrt(3090)

![](./images/test.png)
å®Œï¼
![](./images/dd.png)

